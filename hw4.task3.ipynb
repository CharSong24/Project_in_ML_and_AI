{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7f3b27-94f1-456c-82c7-da0432f98759",
   "metadata": {},
   "source": [
    "# Task 3 (25 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b2164-91ef-42b6-a61b-7ddb491165df",
   "metadata": {},
   "source": [
    "### In this task, use any of the pre-trained word embeddings. The Wor2vec embedding link provided with the lecture notes can be useful to get started. Write your own code/function that uses these embeddings and outputs cosine similarity and a dissimilarity score for any 2 pair of words (read as user input). The dissimilarity score should be defined by you. You either can have your own idea of a dissimilarity score or refer to literature (cite the paper you used). In either case clearly describe how this score helps determine the dissimilarity between 2 words.\n",
    "\n",
    "### Note: Dissimilarity measure has been an important metric for recommender systems trying to introduce ‘Novelty and Diversity’ in assortments (as opposed to only accuracy). You might find different metrics of dissimilarity in recommender system’s literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9f436-4859-4e4e-b216-bed8e6a5b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "# load word2vec\n",
    "word_vectors = api.load('word2vec-google-news-300')\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "    return similarity\n",
    "\n",
    "def dissimilarity_score(word1, word2):\n",
    "    vector1 = word_vectors[word1]\n",
    "    vector2 = word_vectors[word2]\n",
    "    similarity = cosine_similarity(vector1, vector2)\n",
    "\n",
    "    return 1 - similarity\n",
    "\n",
    "# user input\n",
    "word1 = input(\"Enter first word: \")\n",
    "word2 = input(\"Enter second word: \")\n",
    "\n",
    "# cal cosine similarity and a dissimilarity score\n",
    "vector1 = word_vectors[word1] \n",
    "vector2 = word_vectors[word2]  \n",
    "similarity = cosine_similarity(vector1, vector2)\n",
    "dissimilarity = dissimilarity_score(word1, word2)\n",
    "\n",
    "print(f\"Cosine Similarity between '{word1}' and '{word2}': {similarity}\")\n",
    "print(f\"Dissimilarity Score between '{word1}' and '{word2}': {dissimilarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5923f420-faaf-460f-b640-00388de9ece3",
   "metadata": {},
   "source": [
    "Enter first word: hello\n",
    "Enter second word: second\n",
    "Cosine Similarity between 'hello' and 'second': 0.028079349547624588\n",
    "Dissimilarity Score between 'hello' and 'second': 0.9719206504523754"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688e552-1f49-417d-9dfb-3cb0186c790c",
   "metadata": {},
   "source": [
    "The dissimilarity score I defined is calculated by 1 - cosine similarity, which essentially converts cosine similarity into a more intuitive measure of dissimilarity. Cosine similarity itself measures the degree of similarity in direction between two vectors, ranging from -1 to 1, where 1 indicates exactly the same direction, -1 indicates completely opposite directions, and 0 indicates orthogonality (no correlation).\n",
    "\n",
    "When the vectors of two words are exactly the same (cosine similarity is 1), the dissimilarity score will be 0, indicating that these two words are very close or identical in semantics. When the vectors of two words are completely opposite in direction (which is rare in practice because word vectors are usually positive), the theoretical cosine similarity is -1, leading to a dissimilarity score of 2, indicating that these two words are completely different in semantics. For most practical situations, the cosine similarity between two words will be between 0 and 1, hence the dissimilarity score will also be between 0 and 1, with a higher score indicating greater semantic dissimilarity between the two words.\n",
    "\n",
    "### How It Helps Determine Dissimilarity\n",
    "By using the complement of cosine similarity as the dissimilarity score, it provides a direct way to measure and compare the semantic differences between two words. This measurement is very useful for various application scenarios, such as:\n",
    "\n",
    "Recommendation Systems: By calculating the dissimilarity between items, recommendation systems can ensure that the content recommended to users is not only similar to their known preferences but also includes items that offer novelty and diversity.\n",
    "Text Analysis: In text analysis, the dissimilarity score can help identify different topics or concepts within documents or corpora, exploring the diversity of textual content by comparing the dissimilarity of words.\n",
    "Semantic Search: In semantic search applications, the dissimilarity score can be used to exclude results that are not semantically related to the query, thereby improving the accuracy and relevance of search results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
